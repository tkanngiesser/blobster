{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# blobster\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "import fastcore\n",
    "from fastcore.foundation import *\n",
    "import azure\n",
    "from azure.storage.blob import BlockBlobService\n",
    "\n",
    "class AzureBlobStorage:\n",
    "    def __init__(self, credential_file):\n",
    "        \n",
    "        account, key = self.load_credentials(credential_file)\n",
    "        \n",
    "        if account:\n",
    "            self.account = account\n",
    "        else:\n",
    "            self.account = account\n",
    "        if key:\n",
    "            self.key = key\n",
    "        else:\n",
    "            self.key = key\n",
    "        self.is_connected = False\n",
    "        self.blob_service = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def load_credentials(self:AzureBlobStorage, credential_file):\n",
    "    credentials = pd.read_json(credential_file)\n",
    "    return list(credentials['account'].values)[0], list(credentials['key'].values)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading credentials\n",
    "Edit the blob_storage_credentials.json and enter your blob storage account and key information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_blob_storage = AzureBlobStorage(credential_file='blob_storage_credentials.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def connect(self:AzureBlobStorage):\n",
    "    \"\"\"Connect to Azure Blob Storage\"\"\"\n",
    "    self.blob_service = BlockBlobService(\n",
    "        account_name=self.account, account_key=self.key\n",
    "    )\n",
    "    self.is_connected = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connnect to Azure Blob Storage\n",
    "Once the credentials have been loaded with ```load_credentials``` \n",
    "a connection can be established by calling the ```connect```method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_blob_storage.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def list_all_containers(self:AzureBlobStorage):\n",
    "    \"\"\"Return all container names from blob storage\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    container_names: list\n",
    "        all container names in blob storage\n",
    "    \"\"\"\n",
    "    container_names = []\n",
    "    containers = self.blob_service.list_containers()\n",
    "    for container in containers:\n",
    "        container_names.append(container.name)\n",
    "    return container_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vfu-analytics-myhr-employees',\n",
       " 'vfu-analytics-opco',\n",
       " 'vfu-analytics-raw-data',\n",
       " 'vfu-analytics-raw-data-courses',\n",
       " 'vfu-analytics-raw-data-ga-course-launch',\n",
       " 'vfu-analytics-raw-data-ga-course-rating',\n",
       " 'vfu-analytics-raw-data-ga-dashboard-launch',\n",
       " 'vfu-analytics-raw-data-ga-footerlinks',\n",
       " 'vfu-analytics-raw-data-ga-global-navigation',\n",
       " 'vfu-analytics-raw-data-ga-home-academy-sections',\n",
       " 'vfu-analytics-raw-data-ga-notification',\n",
       " 'vfu-analytics-raw-data-ga-ofcourse-launch',\n",
       " 'vfu-analytics-raw-data-ga-ofcourse-pagehits',\n",
       " 'vfu-analytics-raw-data-ga-pagehits',\n",
       " 'vfu-analytics-raw-data-ga-preference-skills-added',\n",
       " 'vfu-analytics-raw-data-ga-preference-skills-removed',\n",
       " 'vfu-analytics-raw-data-ga-saveforlater',\n",
       " 'vfu-analytics-raw-data-ga-searchbox',\n",
       " 'vfu-analytics-raw-data-ga-searchpage',\n",
       " 'vfu-analytics-raw-data-ga-traffic-sources',\n",
       " 'vfu-analytics-raw-data-ga-typeahead',\n",
       " 'vfu-analytics-raw-data-ga-users',\n",
       " 'vfu-analytics-raw-data-nps',\n",
       " 'vfu-analytics-raw-data-ratings',\n",
       " 'vfu-analytics-raw-data-userprofile',\n",
       " 'vfu-analytics-sf-history',\n",
       " 'vfu-asset-implicit-ratings-clean',\n",
       " 'vfu-asset-implicit-ratings-history',\n",
       " 'vfu-asset-implicit-ratings-quality',\n",
       " 'vfu-asset-implicit-ratings-raw',\n",
       " 'vfu-asset-launches-clean',\n",
       " 'vfu-asset-launches-history',\n",
       " 'vfu-asset-launches-quality',\n",
       " 'vfu-asset-launches-raw',\n",
       " 'vfu-asset-ratings-comments-clean',\n",
       " 'vfu-asset-ratings-comments-history',\n",
       " 'vfu-asset-ratings-comments-quality',\n",
       " 'vfu-asset-ratings-comments-raw',\n",
       " 'vfu-assets-clean',\n",
       " 'vfu-assets-history',\n",
       " 'vfu-assets-quality',\n",
       " 'vfu-assets-raw',\n",
       " 'vfu-congnative-search',\n",
       " 'vfu-data-definitions',\n",
       " 'vfu-footerlinks-clean',\n",
       " 'vfu-footerlinks-history',\n",
       " 'vfu-footerlinks-quality',\n",
       " 'vfu-footerlinks-raw',\n",
       " 'vfu-ga-users-clean',\n",
       " 'vfu-ga-users-history',\n",
       " 'vfu-ga-users-quality',\n",
       " 'vfu-ga-users-raw',\n",
       " 'vfu-global-navigation-clean',\n",
       " 'vfu-global-navigation-history',\n",
       " 'vfu-global-navigation-quality',\n",
       " 'vfu-global-navigation-raw',\n",
       " 'vfu-home-academy-sections-clean',\n",
       " 'vfu-home-academy-sections-history',\n",
       " 'vfu-home-academy-sections-quality',\n",
       " 'vfu-home-academy-sections-raw',\n",
       " 'vfu-learner-profiles-clean',\n",
       " 'vfu-learner-profiles-history',\n",
       " 'vfu-learner-profiles-quality',\n",
       " 'vfu-learner-profiles-raw',\n",
       " 'vfu-learners-ga-report-clean',\n",
       " 'vfu-learners-ga-report-history',\n",
       " 'vfu-learners-ga-report-quality',\n",
       " 'vfu-learners-ga-report-raw',\n",
       " 'vfu-lms-asset-events-clean',\n",
       " 'vfu-lms-asset-events-history',\n",
       " 'vfu-lms-asset-events-quality',\n",
       " 'vfu-lms-asset-events-raw',\n",
       " 'vfu-lms-assets-in-progress-clean',\n",
       " 'vfu-lms-assets-in-progress-quality',\n",
       " 'vfu-lms-assets-in-progress-raw',\n",
       " 'vfu-lms-items-completed-raw',\n",
       " 'vfu-notifications-clean',\n",
       " 'vfu-notifications-history',\n",
       " 'vfu-notifications-quality',\n",
       " 'vfu-notifications-raw',\n",
       " 'vfu-nps-clean',\n",
       " 'vfu-nps-history',\n",
       " 'vfu-nps-quality',\n",
       " 'vfu-nps-raw',\n",
       " 'vfu-of-course-me-launches-clean',\n",
       " 'vfu-of-course-me-launches-history',\n",
       " 'vfu-of-course-me-launches-quality',\n",
       " 'vfu-of-course-me-launches-raw',\n",
       " 'vfu-of-course-me-page-hits-clean',\n",
       " 'vfu-of-course-me-page-hits-history',\n",
       " 'vfu-of-course-me-page-hits-quality',\n",
       " 'vfu-of-course-me-page-hits-raw',\n",
       " 'vfu-page-hits-clean',\n",
       " 'vfu-page-hits-history',\n",
       " 'vfu-page-hits-quality',\n",
       " 'vfu-page-hits-raw',\n",
       " 'vfu-preferences-skills-added-clean',\n",
       " 'vfu-preferences-skills-added-history',\n",
       " 'vfu-preferences-skills-added-quality',\n",
       " 'vfu-preferences-skills-added-raw',\n",
       " 'vfu-preferences-skills-removed-clean',\n",
       " 'vfu-preferences-skills-removed-history',\n",
       " 'vfu-preferences-skills-removed-quality',\n",
       " 'vfu-preferences-skills-removed-raw',\n",
       " 'vfu-save-for-later-clean',\n",
       " 'vfu-save-for-later-history',\n",
       " 'vfu-save-for-later-quality',\n",
       " 'vfu-save-for-later-raw',\n",
       " 'vfu-search-box-clean',\n",
       " 'vfu-search-box-history',\n",
       " 'vfu-search-box-quality',\n",
       " 'vfu-search-box-raw',\n",
       " 'vfu-search-page-clean',\n",
       " 'vfu-search-page-history',\n",
       " 'vfu-search-page-quality',\n",
       " 'vfu-search-page-raw',\n",
       " 'vfu-traffic-sources-clean',\n",
       " 'vfu-traffic-sources-history',\n",
       " 'vfu-traffic-sources-quality',\n",
       " 'vfu-traffic-sources-raw',\n",
       " 'vfu-type-ahead-clean',\n",
       " 'vfu-type-ahead-history',\n",
       " 'vfu-type-ahead-quality',\n",
       " 'vfu-type-ahead-raw',\n",
       " 'vfu-user-profiles-clean',\n",
       " 'vfu-user-profiles-history',\n",
       " 'vfu-user-profiles-quality',\n",
       " 'vfu-user-profiles-raw']"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azure_blob_storage.list_all_containers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def delete_container(self:AzureBlobStorage, container_name):\n",
    "    \"\"\"Delete specific container.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    container_name: str\n",
    "        The name of the container that shall be deleted\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None: NoneType\n",
    "    \"\"\"\n",
    "    self.blob_service.delete_container(\n",
    "        container_name=container_name, fail_not_exist=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def make_container(self:AzureBlobStorage, container_name):\n",
    "    \"\"\"Make specific container. First check if container already exists\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    container_name: str\n",
    "        The name of the container that shall be created\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None: NoneType\n",
    "    \"\"\"\n",
    "    try:\n",
    "        self.blob_service.list_blobs(container_name)\n",
    "    except:\n",
    "        # assumption container does not exist and must be created\n",
    "        self.blob_service.create_container(container_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def list_all_blobs(self:AzureBlobStorage, container_name):\n",
    "    blob_names = []\n",
    "    blobs = self.blob_service.list_blobs(container_name)\n",
    "    for blob in blobs:\n",
    "        blob_names.append(blob.name)\n",
    "    return blob_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def delete_blobs(self:AzureBlobStorage, container_name):\n",
    "    \"\"\"Delete all blobs in specified container. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    container_name: str\n",
    "        The name of the container in which all blobs shall be deleted\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None: NoneType\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        blobs = self.blob_service.list_blobs(container_name)\n",
    "    except azure.common.AzureMissingResourceHttpError:\n",
    "        pass\n",
    "        # logger.warning('container not found: {}'.format(container))\n",
    "    else:\n",
    "        for blob in blobs:\n",
    "            self.blob_service.delete_blob(container_name, blob.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def delete_blob(self:AzureBlobStorage, container_name, blob_name):\n",
    "    \"\"\"Delete all blobs in specified container. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    container_name: str\n",
    "        The name of the container of the blob\n",
    "    blob_name: str\n",
    "        The name of the blob that shall be deleted\n",
    "    Returns\n",
    "    -------\n",
    "    None: NoneType\n",
    "    \"\"\"\n",
    "    self.blob_service.delete_blob(container_name, blob_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def file_to_blob(self:AzureBlobStorage, container_name, blob_name, file_name):\n",
    "    self.blob_service.create_blob_from_path(container_name, blob_name, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def folder_to_container(self:AzureBlobStorage, folder_path, container_name=None):\n",
    "    files_in_folder = [f for f in listdir(folder_path) if isfile(join(folder_path, f))]\n",
    "    [self.file_to_blob(container_name=container_name, blob_name=f, file_name=join(folder_path, f)) for f in files_in_folder]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def df_to_blob(self:AzureBlobStorage, container_name, blob_name, df):\n",
    "    \"\"\"Write dataframe to blob\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    container_name: str\n",
    "        The name of the container\n",
    "    \n",
    "    blob_name: str\n",
    "        The name of the blob that shall be created\n",
    "\n",
    "    df: pandas.core.frame.DataFrame\n",
    "        The dataframe that shall be saved as blob\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    extension = blob_name.split(\".\")[-1]\n",
    "    output = io.StringIO()\n",
    "    if extension == \"json\":\n",
    "        output = df.to_json()\n",
    "    elif extension == \"csv\":\n",
    "        output = df.to_csv(index=False, index_label=False)\n",
    "    elif extension == \"parquet\":\n",
    "        output = io.BytesIO()\n",
    "        output = df.to_parquet()\n",
    "    self.blob_service.create_blob_from_text(container_name, blob_name, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def blob_to_df(self:AzureBlobStorage, container_name, blob_name):\n",
    "    \"\"\"Load blob and return dataframe\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    container_name: str\n",
    "        The name of the container\n",
    "\n",
    "    blob_name: str\n",
    "        The name of the blob\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df: pandas.core.frame.DataFrame\n",
    "        The Dataframe containing data of the blob\n",
    "    \"\"\"\n",
    "\n",
    "    extension = blob_name.split(\".\")[-1]\n",
    "\n",
    "    with io.BytesIO() as input_stream:\n",
    "        self.blob_service.get_blob_to_stream(\n",
    "            container_name=container_name, blob_name=blob_name, stream=input_stream\n",
    "        )\n",
    "\n",
    "        input_stream.seek(0)\n",
    "        if extension == \"csv\":\n",
    "            df = pd.read_csv(input_stream, lineterminator=\"\\n\")\n",
    "        elif extension == \"json\":\n",
    "            df = pd.read_json(input_stream)\n",
    "        elif extension == \"parquet\":\n",
    "            df = pd.read_parquet(input_stream)\n",
    "        elif extension == \"xlsx\":\n",
    "            df = pd.read_excel(input_stream)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def blobs_to_df(self:AzureBlobStorage, container_name):\n",
    "    \"\"\"Load blobs and write to dataframe\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    container_name: str\n",
    "        The name of the container\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df: pandas.core.frame.DataFrame\n",
    "        The Dataframe containing data of the blobs\n",
    "    \"\"\"\n",
    "\n",
    "    dfs = []\n",
    "    generator = self.blob_service.list_blobs(container_name)\n",
    "    for blob in generator:\n",
    "        df = self.blob_to_df(container_name, blob.name)\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def copy_blobs_to_other_container(self:AzureBlobStorage, source_container_name, destination_container_name, delete_after_copy=False):\n",
    "    \"\"\"Copy all blobs in one container to another container\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    source_container_name: str\n",
    "        The name of the source container\n",
    "\n",
    "    destination_container_name: str\n",
    "        The name of the target container\n",
    "\n",
    "    delete_after_copy: bool\n",
    "        If True, delete all blobs in source container after copy\n",
    "\n",
    "    \"\"\"\n",
    "    generator = self.blob_service.list_blobs(source_container_name)\n",
    "    for blob in generator:\n",
    "        blob_url = self.blob_service.make_blob_url(source_container_name, blob.name)\n",
    "        self.blob_service.copy_blob(destination_container_name, blob.name, blob_url)\n",
    "    if delete_after_copy:\n",
    "        for blob in generator:\n",
    "            self.blob_service.delete_blob(source_container_name, blob.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def download_blobs_from_container(self:AzureBlobStorage, container_name, destination_path):\n",
    "    \"\"\"Download all blobs from container\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    container_name: str\n",
    "        The name of the container\n",
    "    destination_path: str\n",
    "        The destination path\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    generator = self.blob_service.list_blobs(container_name)\n",
    "\n",
    "    path = Path(download_path)\n",
    "\n",
    "    zf = zipfile.ZipFile(\n",
    "        path / f\"{container_name}.zip\", mode=\"w\", compression=zipfile.ZIP_DEFLATED\n",
    "    )\n",
    "\n",
    "    for blob in generator:\n",
    "        b = self.blob_service.get_blob_to_bytes(container_name, blob.name)\n",
    "        zf.writestr(blob.name, b.content)\n",
    "\n",
    "    zf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
