{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# blobster\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "import fastcore\n",
    "from fastcore.foundation import *\n",
    "import azure\n",
    "from azure.storage.blob import BlockBlobService\n",
    "\n",
    "class AzureBlobStorage:\n",
    "    def __init__(self, credential_file):\n",
    "        \n",
    "        account, key = self.load_credentials(credential_file)\n",
    "        \n",
    "        if account:\n",
    "            self.account = account\n",
    "        else:\n",
    "            self.account = account\n",
    "        if key:\n",
    "            self.key = key\n",
    "        else:\n",
    "            self.key = key\n",
    "        self.is_connected = False\n",
    "        self.blob_service = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def load_credentials(self:AzureBlobStorage, credential_file):\n",
    "    \"\"\"Load Azure Blob Storage credentials from file\"\"\"\n",
    "    credentials = pd.read_json(credential_file)\n",
    "    return list(credentials['account'].values)[0], list(credentials['key'].values)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit the `blob_storage_credentials.json` and enter your blob storage `account` and `key information`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_blob_storage = AzureBlobStorage(credential_file='blob_storage_credentials.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def connect(self:AzureBlobStorage):\n",
    "    \"\"\"Connect to Azure Blob Storage\"\"\"\n",
    "    self.blob_service = BlockBlobService(\n",
    "        account_name=self.account, account_key=self.key\n",
    "    )\n",
    "    self.is_connected = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the credentials have been loaded with ```load_credentials``` \n",
    "a connection can be established by calling the ```connect```method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_blob_storage.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def list_all_containers(self:AzureBlobStorage):\n",
    "    \"\"\"Return all container names from blob storage\"\"\"\n",
    "    container_names = []\n",
    "    containers = self.blob_service.list_containers()\n",
    "    for container in containers:\n",
    "        container_names.append(container.name)\n",
    "    return container_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`azure_blob_storage.list_all_containers()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def delete_container(self:AzureBlobStorage, container_name):\n",
    "    \"\"\"Delete specified container\"\"\"\n",
    "    self.blob_service.delete_container(\n",
    "        container_name=container_name, fail_not_exist=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`azure_blob_storage.delete_container(container_that_shall_be_deleted)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def make_container(self:AzureBlobStorage, container_name):\n",
    "    \"\"\"Make specified container (if it does not exist)\"\"\"\n",
    "    try:\n",
    "        self.blob_service.list_blobs(container_name)\n",
    "    except:\n",
    "        # assumption container does not exist and must be created\n",
    "        self.blob_service.create_container(container_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def list_all_blobs(self:AzureBlobStorage, container_name):\n",
    "    \"\"\"List all blobs in a container\"\"\"\n",
    "    blob_names = []\n",
    "    blobs = self.blob_service.list_blobs(container_name)\n",
    "    for blob in blobs:\n",
    "        blob_names.append(blob.name)\n",
    "    return blob_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def delete_blobs(self:AzureBlobStorage, container_name):\n",
    "    \"\"\"Delete all blobs in specified container\"\"\"\n",
    "    try:\n",
    "        blobs = self.blob_service.list_blobs(container_name)\n",
    "    except azure.common.AzureMissingResourceHttpError:\n",
    "        pass\n",
    "    else:\n",
    "        for blob in blobs:\n",
    "            self.blob_service.delete_blob(container_name, blob.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def delete_blob(self:AzureBlobStorage, container_name, blob_name):\n",
    "    \"\"\"Delete all blobs in specified container\"\"\" \n",
    "    self.blob_service.delete_blob(container_name, blob_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def file_to_blob(self:AzureBlobStorage, container_name, blob_name, file_name):\n",
    "    self.blob_service.create_blob_from_path(container_name, blob_name, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def folder_to_container(self:AzureBlobStorage, folder_path, container_name=None):\n",
    "    \"\"\"Upload all files in a folder to a specified container\"\"\"\n",
    "    files_in_folder = [f for f in listdir(folder_path) if isfile(join(folder_path, f))]\n",
    "    [self.file_to_blob(container_name=container_name, blob_name=f, file_name=join(folder_path, f)) for f in files_in_folder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def df_to_blob(self:AzureBlobStorage, container_name, blob_name, df):\n",
    "    \"\"\"Write Pandas dataframe to blob\"\"\"\n",
    "    extension = blob_name.split(\".\")[-1]\n",
    "    output = io.StringIO()\n",
    "    if extension == \"json\":\n",
    "        output = df.to_json()\n",
    "    elif extension == \"csv\":\n",
    "        output = df.to_csv(index=False, index_label=False)\n",
    "    elif extension == \"parquet\":\n",
    "        output = io.BytesIO()\n",
    "        output = df.to_parquet()\n",
    "    self.blob_service.create_blob_from_text(container_name, blob_name, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def blob_to_df(self:AzureBlobStorage, container_name, blob_name):\n",
    "    \"\"\"Load blob and return Pandas dataframe\"\"\"\n",
    "    extension = blob_name.split(\".\")[-1]\n",
    "\n",
    "    with io.BytesIO() as input_stream:\n",
    "        self.blob_service.get_blob_to_stream(\n",
    "            container_name=container_name, blob_name=blob_name, stream=input_stream\n",
    "        )\n",
    "\n",
    "        input_stream.seek(0)\n",
    "        if extension == \"csv\":\n",
    "            df = pd.read_csv(input_stream, lineterminator=\"\\n\")\n",
    "        elif extension == \"json\":\n",
    "            df = pd.read_json(input_stream)\n",
    "        elif extension == \"parquet\":\n",
    "            df = pd.read_parquet(input_stream)\n",
    "        elif extension == \"xlsx\":\n",
    "            df = pd.read_excel(input_stream)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def blobs_to_df(self:AzureBlobStorage, container_name):\n",
    "    \"\"\"Load blobs and write to Pandas dataframe\"\"\"\n",
    "    dfs = []\n",
    "    generator = self.blob_service.list_blobs(container_name)\n",
    "    for blob in generator:\n",
    "        df = self.blob_to_df(container_name, blob.name)\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def copy_blobs_to_other_container(self:AzureBlobStorage, source_container_name, destination_container_name, delete_after_copy=False):\n",
    "    \"\"\"Copy all blobs in one container to another container\"\"\"\n",
    "    generator = self.blob_service.list_blobs(source_container_name)\n",
    "    for blob in generator:\n",
    "        blob_url = self.blob_service.make_blob_url(source_container_name, blob.name)\n",
    "        self.blob_service.copy_blob(destination_container_name, blob.name, blob_url)\n",
    "    if delete_after_copy:\n",
    "        for blob in generator:\n",
    "            self.blob_service.delete_blob(source_container_name, blob.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def download_blobs_from_container(self:AzureBlobStorage, container_name, destination_path):\n",
    "    \"\"\"Download all blobs from container\"\"\"\n",
    "    generator = self.blob_service.list_blobs(container_name)\n",
    "\n",
    "    path = Path(download_path)\n",
    "\n",
    "    zf = zipfile.ZipFile(\n",
    "        path / f\"{container_name}.zip\", mode=\"w\", compression=zipfile.ZIP_DEFLATED\n",
    "    )\n",
    "\n",
    "    for blob in generator:\n",
    "        b = self.blob_service.get_blob_to_bytes(container_name, blob.name)\n",
    "        zf.writestr(blob.name, b.content)\n",
    "\n",
    "    zf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
